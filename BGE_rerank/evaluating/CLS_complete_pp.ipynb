{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe43f7aa-7b75-4179-aae1-ca676667a607",
   "metadata": {},
   "source": [
    "Embed PM abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d6317-ca22-416b-b7f8-830b75527695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import h5py\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load BGE base model and tokenizer\n",
    "model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.half()  # Convert model to fp16\n",
    "model.to('cuda')  # Move model to GPU\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Load the JSON file with the data\n",
    "input_file = \"/home/jh537/Clinical_Trial_Embending/Clinical_Trial_data/Retrievial/v2_/NEW_PM_id_text.json\"\n",
    "with open(input_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Open the HDF5 file to store the embeddings\n",
    "output_file = \"/n/data1/hsph/biostat/celehs/lab/jh537/Retrivial_task/DATA/CLS_NEW_PM_id_text_W_BGE_L.h5\"\n",
    "with h5py.File(output_file, \"w\") as h5f:\n",
    "    for item in tqdm(data, desc=\"Processing articles\"):\n",
    "        article_id = item[\"article_id\"]\n",
    "        text = item[\"text\"]\n",
    "\n",
    "        # Tokenize the input text\n",
    "        encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
    "\n",
    "        # Generate embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "\n",
    "        # Perform CLS pooling\n",
    "        # Extract the embedding for the [CLS] token (the first token in the sequence)\n",
    "        cls_embedding = model_output.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
    "\n",
    "        # Convert CLS embedding to numpy\n",
    "        cls_embedding = cls_embedding.squeeze().cpu().numpy()\n",
    "\n",
    "        # Store the embeddings in the HDF5 file\n",
    "        h5f.create_dataset(article_id, data=cls_embedding)\n",
    "\n",
    "print(\"Embeddings have been successfully saved to\", output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680cf540-78fa-4c0e-b450-85ac092ec055",
   "metadata": {},
   "source": [
    "Test complete pipeline 10-17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec6db38-17b3-48ac-9330-b75ef4c21365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import h5py\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import faiss\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set top_k values for easier modification\n",
    "top_k_initial = 30\n",
    "top_k_rerank_10 = 10\n",
    "top_k_rerank_1 = 1\n",
    "First_N = 2000\n",
    "\n",
    "# Start measuring time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load BGE base model and tokenizer\n",
    "model_name = \"BAAI/bge-large-en-v1.5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to('cuda')  # Move model to GPU\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Open the HDF5 file and load all embeddings into a list\n",
    "embedding_file = \"/n/data1/hsph/biostat/celehs/lab/jh537/Retrivial_task/DATA/CLS_NEW_PM_id_text_W_BGE_L.h5\"\n",
    "embeddings = []\n",
    "article_ids = []\n",
    "with h5py.File(embedding_file, \"r\") as h5f:\n",
    "    for article_id in h5f.keys():\n",
    "        article_embedding = h5f[article_id][:]\n",
    "        embeddings.append(article_embedding)\n",
    "        article_ids.append(article_id)\n",
    "\n",
    "# Convert embeddings list to a numpy array\n",
    "embeddings = np.array(embeddings, dtype='float32')\n",
    "\n",
    "# Normalize embeddings for cosine similarity\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "# Build a FAISS index (using cosine similarity)\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner Product for cosine similarity\n",
    "index.add(embeddings)\n",
    "\n",
    "# Load the initial JSON input file\n",
    "input_file = \"/home/jh537/Clinical_Trial_Embending/Clinical_Trial_data/Retrievial/v2_/NEW_PM_id_text.json\"\n",
    "with open(input_file, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Load the file with the first First_N summaries\n",
    "summary_file = \"/n/data1/hsph/biostat/celehs/lab/jh537/Retrivial_task/DATA/LONG_CTG_id_text_refs_test.json\"\n",
    "with open(summary_file, \"r\") as f:\n",
    "    summaries_data = json.load(f)\n",
    "\n",
    "# Load the reranker model and tokenizer\n",
    "reranker_model_name = \"/n/data1/hsph/biostat/celehs/lab/jh537/Models/NEW_cop_reranker_HN_10_17\"\n",
    "reranker_tokenizer = AutoTokenizer.from_pretrained(reranker_model_name)\n",
    "reranker_model = AutoModelForSequenceClassification.from_pretrained(reranker_model_name).to('cuda')  # GPU\n",
    "reranker_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Function to perform CLS pooling\n",
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:, 0, :]  # CLS token is at index 0\n",
    "\n",
    "# Track how many times the reference is found in top_k_rerank=10 and top_k_rerank=1\n",
    "found_count_10 = 0\n",
    "found_count_1 = 0\n",
    "\n",
    "# Iterate over the first First_N summaries with a progress bar\n",
    "for summary_item in tqdm(summaries_data[:First_N], desc=\"Processing summaries\"):\n",
    "    query = summary_item['summary']\n",
    "    reference_id = str(summary_item['ref'])\n",
    "\n",
    "    # Tokenize the query\n",
    "    encoded_input = tokenizer(query, padding=True, truncation=True, return_tensors='pt').to('cuda')  # Move input to GPU\n",
    "\n",
    "    # Generate query embedding\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    query_embedding = cls_pooling(model_output).squeeze().cpu().numpy().astype('float32')\n",
    "\n",
    "    # Normalize query embedding for cosine similarity\n",
    "    faiss.normalize_L2(query_embedding.reshape(1, -1))\n",
    "\n",
    "    # Search for the top_k_initial most similar embeddings\n",
    "    scores, indices = index.search(np.array([query_embedding]), top_k_initial)\n",
    "\n",
    "    # Store the top initial article IDs in a list\n",
    "    top_article_ids = [article_ids[idx] for idx in indices[0]]\n",
    "\n",
    "    # Create a dictionary to store the text of the top articles\n",
    "    article_texts = {}\n",
    "    for article_id in top_article_ids:\n",
    "        for item in data:\n",
    "            if item[\"article_id\"] == article_id:\n",
    "                article_texts[article_id] = item[\"text\"]\n",
    "                break\n",
    "\n",
    "    # Prepare the reranking inputs and store the (article_id, score)\n",
    "    rerank_scores = []\n",
    "    for article_id, article_text in article_texts.items():\n",
    "        # Tokenize the concatenation of the query and the article text\n",
    "        inputs = reranker_tokenizer(query, article_text, padding=True,\n",
    "                                    truncation=True, return_tensors='pt').to('cuda')\n",
    "        # Generate reranking score using CLS token\n",
    "        with torch.no_grad():\n",
    "            outputs = reranker_model(**inputs)\n",
    "            cls_embedding = outputs.logits[:, 0]  # Use the CLS token for reranking\n",
    "            score = torch.sigmoid(cls_embedding).squeeze().item()  # Sigmoid to get [0, 1] range\n",
    "        # Store the score along with the article ID\n",
    "        rerank_scores.append((article_id, score))\n",
    "\n",
    "    # Sort the rerank scores in descending order\n",
    "    rerank_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top_k_rerank=10 article IDs\n",
    "    top_10_article_ids = [article_id for (article_id, _) in rerank_scores[:top_k_rerank_10]]\n",
    "\n",
    "    # Get the top_k_rerank=1 article ID (the first in the reranked list, if available)\n",
    "    top_1_article_ids = [article_id for (article_id, _) in rerank_scores[:top_k_rerank_1]]\n",
    "\n",
    "    # Check if the reference ID is in the top 10\n",
    "    if reference_id in top_10_article_ids:\n",
    "        found_count_10 += 1\n",
    "\n",
    "    # Check if the reference ID is in the top 1\n",
    "    if reference_id in top_1_article_ids:\n",
    "        found_count_1 += 1\n",
    "\n",
    "# Calculate the percentage of summaries for which the reference was found\n",
    "percentage_found_10 = (found_count_10 / len(summaries_data[:First_N])) * 100\n",
    "percentage_found_1 = (found_count_1 / len(summaries_data[:First_N])) * 100\n",
    "\n",
    "print(f\"Percentage of summaries with the reference in the top {top_k_rerank_10}: {percentage_found_10:.2f}%\")\n",
    "print(f\"Percentage of summaries with the reference in the top {top_k_rerank_1}: {percentage_found_1:.2f}%\")\n",
    "\n",
    "# Print the total running time\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total running time: {total_time:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
